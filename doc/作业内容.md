# **作业1：ClassWork1_NEUWordsCount.java**

1. 在 CentOS 8 环境下安装 JDK；
2. 在 CentOS 8 环境下部署 Spark（Standalone Mode）；
3. 在 CentOS 8 环境下部署 Hadoop 3.5；
4. 在服务器上运行 Spark 自带任务（计算 Π），并观察任务队列；
5. 搭建本地 IDE 开发环境，进行 Java 编程；
6. 统计文本文件中每个单词（仅包含字母、不含数字）的出现次数；——文件名：**东北大学.txt**；
7. 找出文本文件中出现次数大于等于 4 次的单词；
8. 将文本文件中的单词按字母顺序排序；
9. 找出文本文件中出现次数最多的数字（仅数字）；
10. 对文本文件中的所有数字进行求和操作；
11. **（附加题）** 找出文本文件中出现频率最高的前 N 个单词（N 为运行时用户输入变量）。

---

# **作业2：ClassWork2_SQLSum.java**

1. 在 Windows 环境下安装 MySQL 8；
2. 从给定的 CSV 文件（`t_etl2_jjjyqrxx.csv`）中读取数据，计算每日每种产品的投资者数量；
3. 将计算结果写入数据库表 `spark.t_fund_stat_daily`；
4. 从数据库表 `spark_demo.fairfundasset` 中读取数据，统计当日所有投资者的资产总额（fund total value），并将结果写入表 `t_asset_stat_daily`。

---

# **作业3：ClassWork3_StreamCount.java**

1. 安装并学习使用 netcat 工具，完成环境搭建；
2. 使用 Spark Streaming 编写程序，监听 TCP/IP 套接字 9999 端口，实时读取 socket 数据，并每隔 20 秒计算接收到的每个单词的总出现次数；
3. **（附加题）** 使用 JavaStreamingContext 从本机 9999 端口实时读取日志，每隔 20 秒输出当前收集到的错误日志记录（若某行包含 “error” 单词，则视为错误日志）。
